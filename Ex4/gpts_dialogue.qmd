---
title: "chatGTP API Example 4: chatGPT models dialogue"
format: html
editor: visual
---

```{r}

library(httr)
library(jsonlite)
```

### Function to call OpenAI API for a ChatGPT instance with specific settings.

```{r}

chat_gpt_interaction <- function(messages, api_key, model, temperature = 0.7) {
  url <- "https://api.openai.com/v1/chat/completions"
  
  body <- list(
    model = model,
    messages = messages,
    max_tokens = 150,
    temperature = temperature  # Set the temperature
  )
  
  response <- POST(
    url,
    add_headers(
      `Authorization` = paste("Bearer", api_key),
      `Content-Type` = "application/json"
    ),
    body = toJSON(body, auto_unbox = TRUE),
    encode = "json"
  )
  
  if (status_code(response) != 200) {
    stop("API request failed with status code ", status_code(response), 
         ": ", content(response, as = "text", encoding = "UTF-8"))
  }
  
  # Extract content as text and parse JSON
  content_as_text <- content(response, as = "text", encoding = "UTF-8")
  content <- fromJSON(content_as_text)

  # Ensure that 'choices' has at least one item
  if (length(content[["choices"]]) < 1) {
    stop("No choices found in the response.")
  }

  # Extract the message content using the correct path
  response_text <- content[["choices"]][["message"]][["content"]]

  if (is.null(response_text)) {
    stop("Unable to extract message content from the choice")
  }

  total_tokens <- content[["usage"]][["total_tokens"]]

  return(list(response_text = response_text, total_tokens = total_tokens))
}
```

### Function to append a message to the context with verification for string type.

```{r}

append_message <- function(context, role, content) {
  if (!is.character(content)) {
    stop("Content must be a string.")
  }
  new_message <- list(role = role, content = content)
  return(append(context, list(new_message)))
}
```

### Function to list the folder structure and optionally read file contents.

```{r}

get_folder_structure <- function(dir_path, read_files = FALSE) {
  folder_structure <- list()
  files_and_dirs <- list.files(dir_path, full.names = TRUE)
  
  for (entry in files_and_dirs) {
    entry_name <- basename(entry)
    if (file.info(entry)$isdir) {
      folder_structure[[entry_name]] <- get_folder_structure(entry, read_files)
    } else {
      if (read_files) {
        file_content <- tryCatch({
          readLines(entry)
        }, error = function(e) {
          paste("Error reading file:", e$message)
        })
        folder_structure[[entry_name]] <- paste(file_content, collapse = "\n")
      } else {
        folder_structure[[entry_name]] <- NULL
      }
    }
  }
  return(folder_structure)
}
```

### Function to convert folder structure to readable string for ChatGPT.

```{r}

folder_structure_to_string <- function(folder_structure) {
  folder_string <- ""
  
  for (entry_name in names(folder_structure)) {
    item <- folder_structure[[entry_name]]
    if (is.null(item)) {
      folder_string <- paste(folder_string, entry_name, "(File)", sep = "\n")
    } else {
      folder_string <- paste(folder_string, entry_name, "(Folder):", sep = "\n")
      folder_string <- paste(folder_string, folder_structure_to_string(item), sep = "\n")
    }
  }
  
  return(folder_string)
}
```

### Starting the conversation between models:

```{r}

# Configuration and initial setup
model <- "gpt-3.5-turbo"
# model <- "gpt-4o"

# Get the folder structure in textual form
dir_path <- "/Users/rasools/sdrive/projects/LTS_Frisen/Frisen_gdrive/nbis_frisen_2305"
folder_structure <- get_folder_structure(dir_path, read_files = FALSE)
folder_structure_string <- folder_structure_to_string(folder_structure)

# Initialize the context for ChatGPT instances based on folder structure
context_a <- list(list(role = "system", content = "You are a researcher. Thinking about the data in a project folder and should relevant questions."))
context_a <- append_message(context_a, "user", folder_structure_string)

context_b <- list(list(role = "system", content = "You are an insightful analyst. Answer questions and provide useful information about the folder content."))

# Set temperatures (optional)
temperature_a <- 0.1
temperature_b <- 0.7

# Set the number of interactions and initiate conversation
num_interactions <- 5
current_interaction <- 1

while (current_interaction <= num_interactions) {
  # ChatGPT-A asks a question
  response_a <- chat_gpt_interaction(context_a, Sys.getenv("OPENAI_API_KEY_NBIS"), model, temperature_a)
  message_a <- response_a$response_text
  
  # ChatGPT-B provides an answer
  context_b <- append_message(context_b, "user", message_a)
  response_b <- chat_gpt_interaction(context_b, Sys.getenv("OPENAI_API_KEY_NBIS"), model, temperature_b)
  message_b <- response_b$response_text
  
  # Print the interaction
  cat(sprintf("Interaction %d\n", current_interaction))
  cat("Question from ChatGPT-A:\n", message_a, "\n")
  cat("Answer from ChatGPT-B:\n", message_b, "\n\n")
  
  # Prepare context for the next question
  context_a <- append_message(context_a, "assistant", message_b)

  # Increment the interaction counter
  current_interaction <- current_interaction + 1
}

```
