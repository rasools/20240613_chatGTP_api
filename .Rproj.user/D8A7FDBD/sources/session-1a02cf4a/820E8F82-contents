---
title: "chatGTP API Example 4: chatGPT models dialogue"
format: html
editor: visual
---

```{r}
library(httr)
library(jsonlite)

# Function to list the folder structure and optionally read file contents
get_folder_structure <- function(dir_path, read_files = FALSE) {
  folder_structure <- list()
  files_and_dirs <- list.files(dir_path, full.names = TRUE)
  
  for (entry in files_and_dirs) {
    entry_name <- basename(entry)
    if (file.info(entry)$isdir) {
      folder_structure[[entry_name]] <- get_folder_structure(entry, read_files)
    } else {
      if (read_files) {
        file_content <- tryCatch({
          readLines(entry)
        }, error = function(e) {
          paste("Error reading file:", e)
        })
        folder_structure[[entry_name]] <- paste(file_content, collapse="\n")
      } else {
        folder_structure[[entry_name]] <- NULL
      }
    }
  }
  return(folder_structure)
}

# Folder structure
dir_path <- "/Users/rasools/sdrive/projects/LTS_Frisen/Frisen_gdrive/nbis_frisen_2305"
folder_structure <- get_folder_structure(dir_path, read_files = FALSE)

# Function to interact with ChatGPT and retrieve the response
chat_gpt_interaction <- function(message, api_key, folder_structure = NULL) {
  url <- "https://api.openai.com/v1/chat/completions"
  
  context_message <- if (!is.null(folder_structure)) {
    paste("Here is the folder structure and files:\n", toJSON(folder_structure, pretty = TRUE), "\n\nLet's discuss:")
  } else {
    ""
  }
  
  body <- list(
    model = "gpt-3.5-turbo",
    messages = list(
      list(role = "user", content = message),
      list(role = "system", content = context_message)  # Context message here
    ),
    max_tokens = 150,
    n = 1,
    temperature = 0.7
  )
  
  response <- POST(
    url,
    add_headers("Authorization" = paste("Bearer", Sys.getenv("OPENAI_API_KEY_NBIS")), "Content-Type" = "application/json"),
    body = toJSON(body, auto_unbox = TRUE),
    encode = "json"
  )
  
  if (status_code(response) != 200) {
    stop("API request failed with status code ", status_code(response), ": ", content(response, as = "text", encoding = "UTF-8"))
  }
  
  content <- content(response, as = "text", encoding = "UTF-8")
  
  json_content <- fromJSON(content, flatten = TRUE)
  
  if (length(json_content$choices) > 0 && "message.content" %in% colnames(json_content$choices)) {
    response_text <- json_content$choices[1, "message.content"]
    total_tokens <- json_content$usage$total_tokens[1]
  } else {
    stop("Unexpected response format from API")
  }
  
  return(list(response_text = response_text, total_tokens = total_tokens))
}

# Keeps track of the interaction stage
stage <- 1

# Initial messages for the chatbots based on the stages
initial_messages <- list(
  "Let's discuss the types of data available in the project folder.",
  "Let's discuss the potential analyses that can be performed on the data.",
  "Let's discuss what code/scripts should be used for the analyses."
)

# Initial message for ChatGPT A
message_a <- initial_messages[[stage]]
message_b <- ""

# Number of exchanges
num_exchanges <- 6  # An even number to ensure fair distribution of stages
# Total tokens used
total_tokens <- 0

# Chat loop
for (i in 1:num_exchanges) {
  cat("ChatGPT A says:\n", message_a, "\n\n")
  response_a <- chat_gpt_interaction(message_a, Sys.getenv("OPENAI_API_KEY_NBIS"))
  message_b <- response_a$response_text
  total_tokens <- total_tokens + response_a$total_tokens
  
  cat("ChatGPT B says:\n", message_b, "\n\n")
  
  Sys.sleep(1)  # Adding a delay to simulate real-time chatting
  
  response_b <- chat_gpt_interaction(message_b, Sys.getenv("OPENAI_API_KEY_NBIS"), folder_structure)
  message_a <- response_b$response_text
  total_tokens <- total_tokens + response_b$total_tokens
  
  # Transition to the next stage if the discussion for the current stage is complete
  if (i %% 2 == 0 && stage < length(initial_messages)) {
    stage <- stage + 1
    message_a <- initial_messages[[stage]]
    cat("\n--- Transition to:", initial_messages[[stage]], " ---\n\n")
  }
}

cat("Total tokens used: ", total_tokens, "\n")

```
