---
title: "chatGTP API Example 4: chatGPT models dialogue"
format: html
editor: visual
---

```{r}
library(httr)
library(jsonlite)

# Function to call OpenAI API for either of the models
chat_gpt_interaction <- function(message, api_key, model) {
  url <- "https://api.openai.com/v1/chat/completions"
  
  body <- list(
    model = model,
    messages = list(
      list(role = "user", content = message)
    ),
    max_tokens = 150,
    temperature = 0.7
  )
  
  response <- POST(
    url,
    add_headers(
      `Authorization` = paste("Bearer", api_key),
      `Content-Type` = "application/json"
    ),
    body = toJSON(body, auto_unbox = TRUE),
    encode = "json"
  )
  
  if (status_code(response) != 200) {
    stop("API request failed with status code ", status_code(response), ": ", content(response, as = "text", encoding = "UTF-8"))
  }
  
  content <- content(response, as = "text", encoding = "UTF-8")
  json_content <- fromJSON(content)
  
  if (length(json_content$choices) > 0 && "message.content" %in% colnames(json_content$choices)) {
    response_text <- json_content$choices[[1]]$message$content
    total_tokens <- json_content$usage$total_tokens
  } else {
    stop("Unexpected response format from API")
  }
  
  return(list(response_text = response_text, total_tokens = total_tokens))
}

# Configuration
model_a <- "gpt-3.5-turbo"
model_b <- "gpt-4"  # Hypothetical model

# Initial messages
initial_messages <- list(
  "Let's discuss the types of data available in the project folder.",
  "Let's discuss the potential analyses that can be performed on the data.",
  "Let's discuss what code/scripts should be used for the analyses."
)

stage <- 1
num_exchanges <- 6
total_tokens <- 0

message_a <- initial_messages[[stage]]
message_b <- ""

# Chat loop
for (i in 1:num_exchanges) {
  cat("Model A says:\n", message_a, "\n\n")
  response_a <- chat_gpt_interaction(message_a, Sys.getenv("OPENAI_API_KEY_NBIS"), model_a)
  message_b <- response_a$response_text
  total_tokens <- total_tokens + response_a$total_tokens
  
  cat("Model B says:\n", message_b, "\n\n")
  
  Sys.sleep(1)  # Adding a delay to simulate real-time chatting
  
  response_b <- chat_gpt_interaction(message_b, Sys.getenv("OPENAI_API_KEY_NBIS"), model_b)
  message_a <- response_b$response_text
  total_tokens <- total_tokens + response_b$total_tokens
  
  # Transition to the next stage if the discussion for the current stage is complete
  if (i %% 2 == 0 && stage < length(initial_messages)) {
    stage <- stage + 1
    message_a <- initial_messages[[stage]]
    cat("\n--- Transition to:", initial_messages[[stage]], " ---\n\n")
  }
}

cat("Total tokens used: ", total_tokens, "\n")

```
