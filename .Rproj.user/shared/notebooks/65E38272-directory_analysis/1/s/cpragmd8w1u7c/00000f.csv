"0",""
"0",""
"0","# Function to list the folder structure and optionally read file contents"
"0","get_folder_structure <- function(dir_path, read_files = FALSE) {"
"0","  folder_structure <- list()"
"0","  files_and_dirs <- list.files(dir_path, full.names = TRUE)"
"0","  "
"0","  for (entry in files_and_dirs) {"
"0","    entry_name <- basename(entry)"
"0","    if (file.info(entry)$isdir) {"
"0","      folder_structure[[entry_name]] <- get_folder_structure(entry, read_files)"
"0","    } else {"
"0","      if (read_files) {"
"0","        file_content <- tryCatch({"
"0","          readLines(entry)"
"0","        }, error = function(e) {"
"0","          paste(""Error reading file:"", e)"
"0","        })"
"0","        folder_structure[[entry_name]] <- paste(file_content, collapse=""\n"")"
"0","      } else {"
"0","        folder_structure[[entry_name]] <- NULL"
"0","      }"
"0","    }"
"0","  }"
"0","  return(folder_structure)"
"0","}"
"0",""
"0","# Folder structure"
"0","dir_path <- ""/Users/rasools/sdrive/projects/LTS_Frisen/Frisen_gdrive/nbis_frisen_2305"""
"0","folder_structure <- get_folder_structure(dir_path, read_files = FALSE)"
"0",""
"0","# Function to interact with ChatGPT and retrieve the response"
"0","chat_gpt_interaction <- function(message, api_key, folder_structure = NULL) {"
"0","  url <- ""https://api.openai.com/v1/chat/completions"""
"0","  "
"0","  context_message <- if (!is.null(folder_structure)) {"
"0","    paste(""Here is the folder structure and files:\n"", toJSON(folder_structure, pretty = TRUE), ""\n\nLet's discuss:"")"
"0","  } else {"
"0","    """""
"0","  }"
"0","  "
"0","  body <- list("
"0","    model = ""gpt-3.5-turbo"","
"0","    messages = list("
"0","      list(role = ""system"", content = context_message),  # Context message here"
"0","      list(role = ""user"", content = message)"
"0","    ),"
"0","    max_tokens = 150,"
"0","    n = 1,"
"0","    temperature = 0.7"
"0","  )"
"0","  "
"0","  response <- POST("
"0","    url,"
"0","    add_headers(""Authorization"" = paste(""Bearer"", api_key), ""Content-Type"" = ""application/json""),"
"0","    body = toJSON(body, auto_unbox = TRUE),"
"0","    encode = ""json"""
"0","  )"
"0","  "
"0","  if (status_code(response) != 200) {"
"0","    stop(""API request failed with status code "", status_code(response), "": "", content(response, as = ""text"", encoding = ""UTF-8""))"
"0","  }"
"0","  "
"0","  content <- content(response, as = ""text"", encoding = ""UTF-8"")"
"0","  "
"0","  json_content <- fromJSON(content, flatten = TRUE)"
"0","  "
"0","  if (length(json_content$choices) > 0 && ""message.content"" %in% colnames(json_content$choices)) {"
"0","    response_text <- json_content$choices[1, ""message.content""]"
"0","    total_tokens <- json_content$usage$total_tokens[1]"
"0","  } else {"
"0","    stop(""Unexpected response format from API"")"
"0","  }"
"0","  "
"0","  return(list(response_text = response_text, total_tokens = total_tokens))"
"0","}"
"0",""
"0","initial_message <- ""Let's discuss the types of data available in the project folder."""
"0","message <- initial_message"
"0",""
"0","total_tokens <- 0"
"0","continue_chat <- TRUE"
"0",""
"0","# Chat loop"
"0","while (continue_chat) {"
"0","  cat(""You say:\n"", message, ""\n\n"")"
"0","  "
"0","  response <- chat_gpt_interaction(message, Sys.getenv(""OPENAI_API_KEY_NBIS""), folder_structure)"
"0","  chat_gpt_response <- response$response_text"
"0","  total_tokens <- total_tokens + response$total_tokens"
"0","  "
"0","  cat(""ChatGPT says:\n"", chat_gpt_response, ""\n\n"")"
"0","  "
"0","  Sys.sleep(1)"
"0","  "
"0","  message <- readline(""Your response (type 'exit' to end chat): "")"
"0","  "
"0","  if (tolower(message) == ""exit"") {"
"0","    cat(""You have chosen to end the chat.\n"")"
"0","    continue_chat <- FALSE"
"0","  } else if (message == """") {"
"0","    cat(""No input provided. Ending chat.\n"")"
"0","    continue_chat <- FALSE"
"0","  }"
"0","}"
"1","You say:
"
"1"," "
"1","Let's discuss the types of data available in the project folder."
"1"," "
"1","

"
"1","ChatGPT says:
"
"1"," "
"1","The project folder contains the following types of data:

1. **Example_samples**: This folder may contain example single-cell RNA sequencing (scRNA-seq) data files in h5ad format.

2. **raw_internal**: This folder contains raw data and analysis outputs for the Xenium project. It includes subfolders for specific analysis outputs like clustering, differential expression (diffexp), PCA, and UMAP.

3. **results**: This folder contains logs, reports, and visualizations generated during the analysis of the Xenium project. It includes subfolders for logs, reports, and various visualization outputs like cell type maps, correlation heatmaps, local max plots, tSNE plots, UMAP plots, and venn diagrams.

4. **"
"1"," "
"1","

"
"0","exit§"
"1","You say:
"
"1"," "
"1","exit§"
"1"," "
"1","

"
"1","ChatGPT says:
"
"1"," "
"1","Sure, feel free to return if you have any more questions in the future. Have a great day!"
"1"," "
"1","

"
"0","exit"
"1","You have chosen to end the chat.
"
"0","cat(""Total tokens used: "", total_tokens, ""\n"")"
"1","Total tokens used: "
"1"," "
"1","1946"
"1"," "
"1","
"
"0","cat(""Chat session ended.\n"")"
"1","Chat session ended.
"
